### **08.Data Privacy Approaches in Federated Learning**

| 
**Technique**

 | 

**Purpose**

 | 

**How It Works**

 | 

**Advantages**

 | 

**Limitations**

 |
| --- | --- | --- | --- | --- |
| 

**Secure Multiparty Computation (SMC)**

 | 

Secure communication

 | 

Ensures private aggregation of models in FL rounds

 | 

Prevents direct exposure of model updates

 | 

Doesn't protect against model inversion attacks

 |
| 

**Homomorphic Encryption (HE)**

 | 

Secure model updates

 | 

Encrypts model updates so computations can be performed on encrypted data

 | 

Strong protection against eavesdropping

 | 

Computationally expensive

 |
| 

**Differential Privacy (DP)**

 | 

Hides individual data contribution

 | 

Adds noise to data or model updates to prevent memorization

 | 

Strong privacy guarantees

 | 

Reduces model performance

 |
| 

**Local Differential Privacy (LDP)**

 | 

Ensures individual client privacy

 | 

Adds noise at the client-side before sending updates

 | 

Strongest privacy level

 | 

Can lead to lower accuracy

 |
| 

**Central Differential Privacy (CDP)**

 | 

Hides participation of clients

 | 

Adds noise at the server-side during aggregation

 | 

Balances privacy and performance

 | 

Weaker privacy than LDP

 |